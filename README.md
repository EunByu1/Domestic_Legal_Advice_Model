# [ Domestic_Legal_Advice_Model ]

## 00. Intro 
: To help the general public easily obtain  Korean legal advice, we fine-tuned the Gemma model using QLoRA technology.
<br><br><br>

## 01. Settings
- Colab: T4 GPU
- Hugging Face: Individual Token Required
- Datasets: https://huggingface.co/datasets/zzunyang/LawQA_LawSee/viewer
<br><br><br>

## 02. Experiment
&nbsp;&nbsp; â–¶ You can observe that after fine-tuning, it provides a better explanation of legal advice than before.
- [Before] Fine_Tuning
  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img width="800" alt="image" src="https://github.com/user-attachments/assets/65f8873e-f11c-46c7-91f6-a85d259ee4ac">

<br>

- [After] Fine_Tuning
  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img width="886" alt="image" src="https://github.com/user-attachments/assets/0be56e37-f78c-4bb2-823f-5395b45bf06f">
<br><br><br>

## 03. Addition
: By adjusting the hyperparameters in the provided code, you can obtain more accurate and improved responses compared to the original.
